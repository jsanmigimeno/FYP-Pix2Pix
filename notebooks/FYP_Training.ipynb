{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FYP Training",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsanmigimeno/FYP-Pix2Pix/blob/master/notebooks/FYP_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM8xwGKx0cLA",
        "colab_type": "text"
      },
      "source": [
        "# Mount Google Drive\n",
        "By default, generated files are designed to be saved to a folder named *FYP* on a mounted Google Drive account. If it is not desired to use a Google Drive account, change the variable *rootDir* to point to a valid directory where to save the generated files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqQ3yt990gbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9R30XfD0iBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Default dir\n",
        "rootDir = \"/content/gdrive/My\\ Drive/FYP\"\n",
        "!mkdir rootDir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFkVjmzob0e4",
        "colab_type": "text"
      },
      "source": [
        "# Clone Pix2Pix and install requirements\n",
        "Download the latest available adapted Pix2Pix implementation, and install any requirements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klcTePqIHoEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone code\n",
        "branch = 'master'\n",
        "print(\"Cloning branch %s\" % branch)\n",
        "!git clone --single-branch --branch $branch https://github.com/jsanmigimeno/FYP-Pix2Pix.git\n",
        "  \n",
        "# Install requirements\n",
        "%cd FYP-Pix2Pix\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpcEaH8L91P6",
        "colab_type": "text"
      },
      "source": [
        "## Update Local Code\n",
        "If desired, download a new version of the code without deleting any downloaded datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU5IEauBNLh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Updating code from branch %s\" % branch)\n",
        "% cd ..\n",
        "# Move dataset folder outside code directory\n",
        "!mv ./FYP-Pix2Pix/DatasetsData ./\n",
        "# Remove code directory\n",
        "!rm -rf FYP-Pix2Pix/\n",
        "# Clone new code\n",
        "!git clone --single-branch --branch $branch https://github.com/jsanmigimeno/FYP-Pix2Pix.git\n",
        "# Move dataset folder back into code directory\n",
        "!mv ./DatasetsData ./FYP-Pix2Pix\n",
        "%cd FYP-Pix2Pix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJJn7KLAnOrB",
        "colab_type": "text"
      },
      "source": [
        "# Get dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aimR4WU487nd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download dataset\n",
        "dataset = 'DSLog'  # 'Downscaled_All_JPEG' or 'DSLog'\n",
        "\n",
        "!mkdir ./DatasetsData/\n",
        "!python ./scripts/DatasetURLs.py -p './DatasetsData/' -d $dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLN6FM8qpjCU",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtsaallbY1K-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def paramsListToString(paramsList):\n",
        "  m = \"\"\n",
        "  for param in paramsList:\n",
        "    m += str(param) + \" \"\n",
        "  return m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQNVSWo4UETI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "trainingName = 'trainingName'\n",
        "\n",
        "params = [\n",
        "    # Basic model parameters\n",
        "    \"--model\", \"pix2pix\",                           # Model pix2pix\n",
        "    \"--display_id\", 0,                              # Disable visdom\n",
        "    \"--checkpoints_dir\", rootDir,                   # Path to save checkpoints and logs\n",
        "    \"--dataroot\", './DatasetsData/' + dataset,      # Dataset path './Downscaled_All_JPEG/'\n",
        "    \"--name\", trainingName,                         # Training name\n",
        "    \"--use_validation\",                             # Use validation whilst training\n",
        "    \n",
        "    # Dataset parameters\n",
        "    \"--dataset_mode\", \"aligned\",                    # Aligned dataset mode (AB concatenated)\n",
        "    \"--load_size\", 2120,                            # Resolution to which load images with (width) (default: 2120)\n",
        "    \"--crop_size\", 256,                             # Size to which to crop the images for training (default: 256)\n",
        "    \"--preprocess\", \"crop\",                         # Type of preprocessing (default: crop, NOTE THAT LOAD SIZE IS IGNORED WITH THIS SETTING)\n",
        "    \n",
        "    # Log parameters\n",
        "    \"--save_epoch_freq\", 10,                        # Frequency at which to save the model (default: 5)\n",
        "    \"--save_opt_freq\", 10,                          # Frequency at which to save the optimiser (default: 20)\n",
        "    \"--niter\", 100,                                 # Number of iterations at starting learning rate (default: 100)\n",
        "    \"--niter_decay\", 100,                           # Number of iterations to linearly decay learning rate to zero (default: 100)\n",
        "    \n",
        "    # Loss parameters\n",
        "    \"--lambda_GAN\", 1,                              # GAN loss multiplier (default: 1)\n",
        "    \"--lambda_L1\", 100,                             # L1 coefficient loss (default: 100)\n",
        "    \"--lambda_desc\", 100,                           # Matching coefficient loss (default: 0 - i.e. disabled)\n",
        "    #\"--siamese_descriptor\",                        # Use siamese descriptor\n",
        "    #\"--per_channel_descriptor\"                     # Use per RGB channel descriptors\n",
        "    #\"--descriptor\", \"HardNet\"                      # Type of descriptor to use for the loss\n",
        "    #\"--non_empty_patches_only\"\n",
        "]\n",
        "\n",
        "# Continue training from saved epoch\n",
        "continueTrain = False                               # Whether to resume training (default: False)\n",
        "epoch = 0                                           # Epoch from which to resume training\n",
        "\n",
        "contTrainParams = [\n",
        "    # Resume training parameters\n",
        "    \"--continue_train\",                             # Resume training\n",
        "    \"--epoch\", epoch,                               # Epoch from which to resume training\n",
        "    \"--epoch_count\", epoch + 1,                     # Epoch count from which to resume training \n",
        "]\n",
        "\n",
        "if continueTrain:\n",
        "  params = params + contTrainParams\n",
        "\n",
        "paramsString = paramsListToString(params)\n",
        "\n",
        "!python train.py $paramsString"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}